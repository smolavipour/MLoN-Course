{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "import random\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing of data\n",
    "# Function to load data\n",
    "\n",
    "def get_power_data():\n",
    "    \"\"\"\n",
    "    Read the Individual household electric power consumption dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assume that the dataset is located on folder \"data\"\n",
    "    data = pd.read_csv('data/household_power_consumption.txt',\n",
    "                       sep=';', low_memory=False)\n",
    "\n",
    "    # Drop some non-predictive variables\n",
    "    data = data.drop(columns=['Date', 'Time'], axis=1)\n",
    "\n",
    "    #print(data.head())\n",
    "\n",
    "    # Replace missing values\n",
    "    data = data.replace('?', np.nan)\n",
    "\n",
    "    # Drop NA\n",
    "    data = data.dropna(axis=0)\n",
    "\n",
    "    # Normalize\n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    np_scaled = standard_scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(np_scaled)\n",
    "\n",
    "    # Goal variable assumed to be the first\n",
    "    X = data.values[:, 1:].astype('float32')\n",
    "    y = data.values[:, 0].astype('float32')\n",
    "\n",
    "    # Create categorical y for binary classification with balanced classes\n",
    "    y = np.sign(y+0.46)\n",
    "\n",
    "    # Split train and test data here: (X_train, Y_train, X_test, Y_test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    no_class = 2                 #binary classification\n",
    "\n",
    "    return X_train.T, X_test.T, y_train, y_test, no_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X,y types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "X size (6, 1536960)\n",
      "Y size (1536960,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, no_class = get_power_data()\n",
    "print(\"X,y types: {} {}\".format(type(X_train), type(y_train)))\n",
    "print(\"X size {}\".format(X_train.shape))\n",
    "print(\"Y size {}\".format(y_train.shape))\n",
    "\n",
    "# Create a binary variable from one of the columns.\n",
    "# You can use this OR not\n",
    "\n",
    "idx = y_train >= 0\n",
    "notidx = y_train < 0\n",
    "y_train[idx] = 1\n",
    "y_train[notidx] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\n",
    "\\begin{align}\n",
    "    E=\\min_{w_3, W_2,W_1} \\frac{1}{N}\\sum_i || w_3 s(W_2 s(W_1 x_i)-y_i)||^2   \n",
    "\\end{align}\n",
    "\n",
    "## Layer 3\n",
    "Define \n",
    "\\begin{align}\n",
    "a_3(x)& :=w_3 s(W_2 s(W_1 x))\\\\\n",
    "a_2(x)& :=s(W_2 s(W_1 x)),\\\\\n",
    "a_1(x)& :=s(W_1 x).\n",
    "\\end{align}\n",
    "\n",
    "Then\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial w_3} &= \\frac{2}{N}(a_3-t)\\frac{\\partial a_3}{\\partial w_3} \\\\\n",
    "&=\\frac{2}{N}(x_3-t)\\frac{\\partial w_3a_2}{\\partial w_3}\\\\\n",
    "&=\\frac{2}{N}(x_3-t)a_2^T\\\\\n",
    "\\end{align}\n",
    "\n",
    "So defining \n",
    "$$\\delta_3 := \\frac{2}{N}(a_3-t),$$\n",
    "then\n",
    "$$\\frac{\\partial E}{\\partial w_3} =\\delta_3\\,a_2^T.$$\n",
    "\n",
    "## Layer 2\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E}{\\partial W_2} &= \\frac{2}{N}(a_3-t)\\frac{\\partial a_3}{\\partial W_2} \\\\\n",
    "&=\\frac{2}{N}(a_3-t)\\frac{\\partial (W_3 a_2)}{\\partial W_2}\\\\\n",
    "&=\\delta_3\\frac{\\partial (W_3 a_2)}{\\partial W_2}\\\\\n",
    "&=W_3^T\\delta_3\\frac{\\partial a_2}{\\partial W_2}\\\\\n",
    "&=[W_3^T\\delta_3 \\circ s'(W_2 a_1)]\\frac{\\partial W_2 a_1}{\\partial W_2}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "So defining $$\\delta_2 :=W_3^T\\delta_3 \\circ s'(W_2 a_1),$$\n",
    "we have\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial W_2}=\\delta_2 a_1^T$$\n",
    "\n",
    "## Layer 1\n",
    "\n",
    "Define \n",
    "$$\\delta_1 :=W_2^T\\delta_2 \\circ s'(W_1x),$$\n",
    "similar to layer_2:\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E}{\\partial W_1} &=\\delta_1x^T\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x, derivative=False):\n",
    "    sigm = 1. / (1. + np.exp(-x))\n",
    "    if derivative:\n",
    "        return sigm * (1. - sigm)\n",
    "    return sigm\n",
    "\n",
    "# Define weights initialization\n",
    "def initialize_w(N, d):\n",
    "    return 2*np.random.random((N,d)) - 1\n",
    "\n",
    "# Fill in feed forward propagation\n",
    "def feed_forward_propagation(X, y, w_1, w_2, w_3, lmbda):\n",
    "    # Fill in\n",
    "    #X is q x n\n",
    "    # w_1 is p x q\n",
    "    # w_2 is p x p\n",
    "    # w_3 is 1 x p\n",
    "    layer_0=X # q x n\n",
    "    layer_1=sigmoid(np.matmul(w_1 , X)) # p x n \n",
    "    layer_2=sigmoid(np.matmul(w_2 , layer_1)) # p x n \n",
    "    layer_3=np.matmul(w_3 , layer_2) # p x n\n",
    "    return layer_0, layer_1, layer_2, layer_3\n",
    "\n",
    "\n",
    "# Fill in backpropagation    \n",
    "def back_propagation(y, w_1, w_2, w_3, layer_0, layer_1, layer_2, layer_3):\n",
    "    # Calculate the gradient here\n",
    "    N = y.shape[0]    \n",
    "        \n",
    "    delta3=2/N*(layer_3 - y)\n",
    "    delta2=np.multiply(np.matmul(w_3.T,delta3),sigmoid(np.matmul(w_2,layer_1),derivative=True))\n",
    "    delta1=np.multiply(np.matmul(w_2.T,delta2),sigmoid(np.matmul(w_1,layer_0),derivative=True))\n",
    "    \n",
    "    layer_3_delta=np.matmul(delta3,layer_2.T)\n",
    "    layer_2_delta=np.matmul(delta2,layer_1.T)\n",
    "    layer_1_delta=np.matmul(delta1,layer_0.T)\n",
    "\n",
    "    return layer_1_delta, layer_2_delta, layer_3_delta\n",
    "\n",
    "\n",
    "# Cost function\n",
    "def cost(X, y, w_1, w_2, w_3, lmbda):\n",
    "    N, d = X.shape\n",
    "    a1,a2,a3,a4 = feed_forward_propagation(X,y,w_1,w_2,w_3,lmbda)\n",
    "\n",
    "    return np.linalg.norm(a4[:,0] - y,2) ** 2 / N\n",
    "\n",
    "# Funtion to get mini batch sgd\n",
    "def miniBatch(x,y,batchSize):\n",
    "    D,N = x.shape\n",
    "    X_mini = np.zeros((D,batchSize))\n",
    "    Y_mini = np.zeros((batchSize,))\n",
    "    indexArray = random.sample(range(N), batchSize)\n",
    "    for i in range(batchSize):\n",
    "        X_mini[:,i] = x[:,indexArray[i]]\n",
    "        Y_mini[i,] = y[indexArray[i],]\n",
    "    return X_mini,Y_mini\n",
    "\n",
    "# Define SGD\n",
    "def SGD(X, y, w_1, w_2, w_3, lmbda, learning_rate, batch_size, iterations):\n",
    "    \n",
    "    for i in range(iterations):\n",
    "\n",
    "        X_mini,Y_mini = miniBatch(X,y,batch_size)\n",
    "        L0,L1,L2,L3 = feed_forward_propagation(X_mini,Y_mini,w_1,w_2,w_3,lmbda)\n",
    "        D1,D2,D3 = back_propagation(Y_mini,w_1,w_2,w_3,L0,L1,L2,L3)\n",
    "\n",
    "        #cost1 = cost(X_mini, Y_mini, w_1, w_2, w_3, lmbda)\n",
    "        \n",
    "        a = w_1-(learning_rate*D1).reshape(w_1.shape)\n",
    "        b = w_2-(learning_rate*D2).reshape(w_2.shape)\n",
    "        c = w_3-(learning_rate*D3).reshape(w_3.shape)\n",
    "        \n",
    "        #cost2 = cost(X_mini, Y_mini, a, b, c, lmbda)\n",
    "    \n",
    "        #if ((cost2-cost1)/cost1>0.5):\n",
    "        #    break\n",
    "        \n",
    "        w_1 = a\n",
    "        w_2 = b\n",
    "        w_3 = c\n",
    "        print(i,': ', cost(X,y,w_1,w_2,w_3,lmbda=lmbda))        \n",
    "    return w_1, w_2, w_3\n",
    "\n",
    "# Define SVRG here:\n",
    "def SVRG(X, y, w_1, w_2, w_3, lmbda, learning_rate, T,iterations):\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        K  = floor(iterations/T)\n",
    "        N  = X.shape[1]\n",
    "        wk_1= w_1\n",
    "        wk_2= w_2\n",
    "        wk_3= w_3\n",
    "        \n",
    "        for k in range(K):\n",
    "            L0,L1,L2,L3 = feed_forward_propagation(X,y,w_1,w_2,w_3,lmbda)\n",
    "            ga_1, ga_2, ga_3 = back_propagation(y,wk_1,wk_2,wk_3,L0,L1,L2,L3) #the average\n",
    "            \n",
    "            for t in range(T):\n",
    "                index = np.random.randint(N, size=1)\n",
    "                \n",
    "                L0,L1,L2,L3 = feed_forward_propagation(X[:,index],y[index,],w_1,w_2,w_3,lmbda)\n",
    "                g1_1,g1_2,g1_3 = back_propagation(y[index,], w_1,w_2,w_3,L0,L1,L2,L3)\n",
    "                \n",
    "                Lk0,Lk1,Lk2,Lk3 = feed_forward_propagation(X[:,index],y[index,],wk_1,wk_2,wk_3,lmbda)\n",
    "                g2_1,g2_2,g2_3 = back_propagation(y[index,], wk_1,wk_2,wk_3,Lk0,Lk1,Lk2,Lk3)\n",
    "                \n",
    "                g1  = g1_1 - g2_1 + ga_1\n",
    "                g2  = g1_2 - g2_2 + ga_2\n",
    "                g3  = g1_3 - g2_3 + ga_3\n",
    "\n",
    "                #cost1 = cost(X, y, w_1, w_2, w_3, lmbda)\n",
    "            \n",
    "                a = w_1-(learning_rate*g1).reshape(w_1.shape)\n",
    "                b = w_2-(learning_rate*g2).reshape(w_2.shape)\n",
    "                c = w_3-(learning_rate*g3).reshape(w_3.shape)\n",
    "            \n",
    "                #cost2 = cost(X_mini, Y_mini, a, b, c, lmbda)\n",
    "    \n",
    "                #if ((cost2-cost1)/cost1>0.5):\n",
    "                #    break\n",
    "                  \n",
    "            \n",
    "                w_1 = a\n",
    "                w_2 = b\n",
    "                w_3 = c\n",
    "\n",
    "            wk_1 = w_1\n",
    "            wk_2 = w_2\n",
    "            wk_3 = w_3\n",
    "        print(i,': ', cost(X,y,w_1,w_2,w_3,lmbda=lmbda))        \n",
    "    return w_1, w_2, w_3\n",
    "\n",
    "# Define GD here:\n",
    "def GD(X, y, w_1,w_2,w_3, learning_rate, lmbda, iterations):\n",
    "\n",
    "    for i in range(iterations):    \n",
    "        L0,L1,L2,L3 = feed_forward_propagation(X,y,w_1,w_2,w_3,lmbda)\n",
    "        D1,D2,D3 = back_propagation(y,w_1,w_2,w_3,L0,L1,L2,L3)\n",
    "    \n",
    "        #cost1 = cost(X, y, w_1, w_2, w_3, lmbda)\n",
    "        \n",
    "        a = w_1-(learning_rate*D1).reshape(w_1.shape)\n",
    "        b = w_2-(learning_rate*D2).reshape(w_2.shape)\n",
    "        c = w_3-(learning_rate*D3).reshape(w_3.shape)\n",
    "        \n",
    "        #cost2 = cost(X, y, a, b, c, lmbda)\n",
    "    \n",
    "        #if ((cost2-cost1)/cost1>0.5):\n",
    "        #    break\n",
    "    \n",
    "        w_1 = a\n",
    "        w_2 = b\n",
    "        w_3 = c\n",
    "        print(i,': ', cost(X,y,w_1,w_2,w_3,lmbda=lmbda))        \n",
    "    \n",
    "    return w_1, w_2, w_3\n",
    "\n",
    "# Define projected GD here:\n",
    "def PGD(X, y, w_1,w_2,w_3, learning_rate, lmbda, iterations, noise):\n",
    "    # Complete here:\n",
    "    \n",
    "    return w_1, w_2, w_3\n",
    "\n",
    "# Define BCD here:\n",
    "def BCD(X, y, w_1,w_2,w_3, learning_rate, lmbda, iterations):\n",
    "    # Complete here:\n",
    "    \n",
    "    return w_1, w_2, w_3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--iterations'], dest='iterations', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be a hyperparameter that you tune, not an argument - Fill in the values\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lambda', type=float, default=0.1, dest='lmbda') \n",
    "parser.add_argument('--w_size', type=int, default=3, dest='w_size')\n",
    "parser.add_argument('--lr', type=float, default=0.1)\n",
    "parser.add_argument('--iterations', type=int, default=100)\n",
    "\n",
    "#args = parser.parse_args()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6)\n",
      "(3, 3)\n",
      "(1, 3)\n",
      "(6, 1536960)\n",
      "(1536960,)\n",
      "0 :  276354.43197827035\n",
      "1 :  269124.48233849666\n",
      "2 :  264370.10250831017\n",
      "3 :  261261.74667032715\n",
      "4 :  259248.19936452515\n",
      "5 :  257961.62821370878\n",
      "6 :  257156.08122641404\n",
      "7 :  256667.06076916543\n",
      "8 :  256384.68365730604\n",
      "9 :  256235.7422634473\n",
      "Initial Cost: 287317.49150864885\n",
      "Initial Cost: 256235.7422634473\n"
     ]
    }
   ],
   "source": [
    "w_1 = initialize_w(3,X_train.shape[0])\n",
    "w_2 = initialize_w(3,3)\n",
    "w_3 = initialize_w(1,3)\n",
    "lmbda=0.1\n",
    "print(w_1.shape)\n",
    "print(w_2.shape)\n",
    "print(w_3.shape)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "initialCost=cost(X_train,y_train,w_1,w_2,w_3,lmbda)\n",
    "layer_0,layer_1,layer_2,layer_3 = feed_forward_propagation(X_train,y_train,w_1,w_2,w_3,lmbda)\n",
    "#print('cost: ',costx)\n",
    "\n",
    "w_1_s,w_2_s,w_3_s = GD(X_train, y_train, w_1,w_2,w_3, learning_rate = 0.1, lmbda=lmbda, iterations=10)\n",
    "finalCost=cost(X_train,y_train,w_1_s,w_2_s,w_3_s,lmbda)\n",
    "print('Initial Cost:',initialCost)\n",
    "print('Initial Cost:',finalCost)\n",
    "#d1,d2,d3 = back_propagation(y_train, w_1, w_2, w_3, layer_0,layer_1,layer_2,layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  341668.22407190833\n",
      "1 :  323609.2344836599\n",
      "2 :  309696.54967288714\n",
      "3 :  299274.5250727535\n",
      "4 :  292964.09983598336\n",
      "5 :  284671.29434684635\n",
      "6 :  276202.4298221254\n",
      "7 :  270683.14151518454\n",
      "8 :  267165.6341329409\n",
      "9 :  265010.5291433944\n",
      "10 :  263077.8888569198\n",
      "11 :  262175.14883577405\n",
      "12 :  260724.10405093024\n",
      "13 :  258904.3950195528\n",
      "14 :  258483.0741386785\n",
      "15 :  258140.32664012132\n",
      "16 :  257853.27577987572\n",
      "17 :  257594.1189225933\n",
      "18 :  256669.22904976993\n",
      "19 :  256447.64151588836\n",
      "Initial cost: 370940.29838883615\n",
      "Final cost: 256447.64151588836\n"
     ]
    }
   ],
   "source": [
    "w_1 = initialize_w(3,X_train.shape[0])\n",
    "w_2 = initialize_w(3,3)\n",
    "w_3 = initialize_w(1,3)\n",
    "lmbda=0.1\n",
    "#SGD(X, y, w_1, w_2, w_3, lmbda, learning_rate, batch_size, iterations):\n",
    "initialCost = cost(X_train,y_train,w_1,w_2,w_3,lmbda=0.1)\n",
    "s1,s2,s3 = SGD(X_train, y_train, w_1, w_2, w_3, lmbda=0.1, learning_rate=0.05,batch_size=100,iterations=20)\n",
    "finalCost = cost(X_train,y_train,s1,s2,s3,0.1)\n",
    "print('Initial cost:',initialCost)\n",
    "print('Final cost:',finalCost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  329393.9112000158\n",
      "1 :  480578.4085409427\n",
      "2 :  469788.73202624946\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-6e10703a5e18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mw_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialize_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minitialCost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVRG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfinalCost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Initial cost:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitialCost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-3b4d2afbca7d>\u001b[0m in \u001b[0;36mSVRG\u001b[1;34m(X, y, w_1, w_2, w_3, lmbda, learning_rate, T, iterations)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[0mL0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_forward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                 \u001b[0mg1_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg1_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg1_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mback_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                 \u001b[0mLk0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLk1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLk2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLk3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_forward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwk_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwk_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwk_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-3b4d2afbca7d>\u001b[0m in \u001b[0;36mback_propagation\u001b[1;34m(y, w_1, w_2, w_3, layer_0, layer_1, layer_2, layer_3)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mlayer_3_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mlayer_2_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mlayer_1_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_1_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_2_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_3_delta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w_1 = initialize_w(3,X_train.shape[0])\n",
    "w_2 = initialize_w(3,3)\n",
    "w_3 = initialize_w(1,3)\n",
    "initialCost = cost(X_train,y_train,w_1,w_2,w_3,lmbda=0.1)\n",
    "s1,s2,s3 = SVRG(X_train, y_train, w_1, w_2, w_3, lmbda=0.1, learning_rate=0.05,T=100,iterations=200)\n",
    "finalCost = cost(X_train,y_train,s1,s2,s3,lmbda=0.1)\n",
    "print('Initial cost:',initialCost)\n",
    "print('Final cost:',finalCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-105-39a1d18e33d7>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-105-39a1d18e33d7>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    parser.add_argument('--lambda', type=float, default=, dest='lmbda')\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Should be a hyperparameter that you tune, not an argument - Fill in the values\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lambda', type=float, default=, dest='lmbda') \n",
    "parser.add_argument('--w_size', type=int, default=, dest='w_size')\n",
    "parser.add_argument('--lr', type=float, default=)\n",
    "parser.add_argument('--iterations', type=int, default=)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Initialize weights\n",
    "w_1 = initialize_w(X_train.shape[0], args.w_size)\n",
    "\n",
    "w_2 = initialize_w(args.w_size,args.w_size)\n",
    "\n",
    "w_3 = initialize_w(args.w_size, 1)\n",
    "\n",
    "# Get iterations\n",
    "iterations = args.iterations\n",
    "# Define plotting variables\n",
    "fig, ax = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "# Define the optimizers for the loop\n",
    "optimizers = [\n",
    "        {# Fill in the hyperparameters\n",
    "            \"opt\": SGD(X_train, y_train, w_1, w_2, w_3, args.lmbda, args.lr, batch_size),\n",
    "            \"name\": \"SGD\",\n",
    "            \"inner\": # Fill in\n",
    "        },\n",
    "        {# Fill in the hyperparameters\n",
    "            \"opt\": SVRG(X_train, y_train, w_1, w_2, w_3, args.lmbda, args.lr),\n",
    "            \"name\": \"SVRG\",\n",
    "            \"inner\": # Fill in\n",
    "        },\n",
    "        {# Fill in the hyperparameters\n",
    "            \"opt\": GD(\n",
    "                X_train, y_train, w_1, w_2, w_3, learning_rate=args.lr,\n",
    "                lmbda=args.lmbda, iterations=iterations),\n",
    "            \"name\": \"GD\",\n",
    "            \"inner\": # Fill in\n",
    "        },\n",
    "        {# Fill in the hyperparameters\n",
    "            \"opt\": PGD(\n",
    "                X_train, y_train, w_1, w_2, w_3, learning_rate=args.lr,\n",
    "                lmbda=args.lmbda, iterations=iterations, noise=),\n",
    "            \"name\": \"PGD\",\n",
    "            \"inner\": # Fill in\n",
    "        },\n",
    "        {# Fill in the hyperparameters\n",
    "            \"opt\": BCD(\n",
    "                X_train, y_train, w_1, w_2, w_3, learning_rate=args.lr,\n",
    "                lmbda=args.lmbda, iterations=iterations),\n",
    "            \"name\": \"BCD\",\n",
    "            \"inner\": # Fill in\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the iterates over the algorithms above\n",
    "\n",
    "for opt in optimizers:\n",
    "    #\n",
    "    # Fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "ax[0].legend(loc=\"upper right\")\n",
    "ax[0].set_xlabel(r\"Iteration\", fontsize=16)\n",
    "ax[0].set_ylabel(\"Loss\", fontsize=16)\n",
    "ax[0].set_title(\"CA3 - Training a deep neural network for the power consumption Dataset\")\n",
    "ax[0].set_ylim(ymin=0)\n",
    "\n",
    "ax[1].legend(loc=\"upper right\")\n",
    "ax[1].set_xlabel(r\"Time [s]\", fontsize=16)\n",
    "ax[1].set_ylabel(\"Loss\", fontsize=16)\n",
    "ax[1].set_ylim(ymin=0)\n",
    "\n",
    "plt.savefig(\"power.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
