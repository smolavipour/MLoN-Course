{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports from libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import resource\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5231, 2920)\n",
      "(1, 2920)\n"
     ]
    }
   ],
   "source": [
    "## Preprocessing of data\n",
    "# Load data here:\n",
    "path = Path(Path().absolute())\n",
    "DataPath=str(path.parent)+'/Data/'\n",
    "\n",
    "#taking the last element of data as y\n",
    "X_=np.ndarray((0,16*327-1))\n",
    "Y_=np.ndarray((0,1))\n",
    "\n",
    "#2921\n",
    "for i in range(2920):\n",
    "    #print(i)\n",
    "    f_name=DataPath+'ghg_data/ghg.gid.site'+format(i+2,'04d')+'.dat'\n",
    "    #print(f_name)\n",
    "    data = pd.read_csv(f_name, sep=\" \",header=None)\n",
    "    #print(data.shape)\n",
    "    X = data.iloc[:,:]\n",
    "    Y = data.iloc[15,-1]\n",
    "\n",
    "    X = np.array(X).reshape(1,X.size)[:,0:-1]\n",
    "    Y = np.array(Y).reshape(1,Y.size)\n",
    "    X[np.isnan(X)] = 0\n",
    "    Y[np.isnan(Y)] = 0\n",
    "    \n",
    "    X = X.astype(float)\n",
    "    Y = Y.astype(float)\n",
    "    \n",
    "    X_=np.append(X_,X,axis=0)\n",
    "    Y_=np.append(Y_,Y,axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "X_=X_.T\n",
    "Y_=Y_.T\n",
    "\n",
    "print(X_.shape)\n",
    "print(Y_.shape)\n",
    "\n",
    "pd.DataFrame(X_).to_csv(DataPath+\"data_x.csv\",index=None)\n",
    "pd.DataFrame(Y_).to_csv(DataPath+\"data_y.csv\",index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5231, 1460)\n",
      "(5231, 1460)\n",
      "(1460,)\n",
      "(1460,)\n"
     ]
    }
   ],
   "source": [
    "# Split train and test data here: (X_train, Y_train, X_test, Y_test)\n",
    "X_train=X_[:,0:X_.shape[1]//2]\n",
    "Y_train=Y_[0,0:Y_.shape[1]//2]\n",
    "\n",
    "X_test=X_[:,X_.shape[1]//2:]\n",
    "Y_test=Y_[0,Y_.shape[1]//2:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the gradient\n",
    "\n",
    "The gradient of f(w) can be derived as follows:\n",
    "\\begin{align}\n",
    "\\nabla f= \\frac{1}{N}\\sum_{i\\in[N]}\\frac{-y_i}{e^{y_i w^T x_i}+1}x_i + 2\\lambda w\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.30874759e-05]\n",
      " [3.30680220e-05]\n",
      " [2.65056001e-03]\n",
      " ...\n",
      " [5.47180046e+00]\n",
      " [5.21106825e+00]\n",
      " [4.94483099e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "## Logistic ridge regression with different optimizers\n",
    "# cost function and gradient calculation\n",
    "\n",
    "def cost(x,y,w,lambda_ = 0.01):\n",
    "    D, N = x.shape\n",
    "    value = 0\n",
    "    for i in range(N):\n",
    "        Z = -1 * y[i] * np.matmul(w.T , (x[:,i]).reshape(D,1))\n",
    "        value += np.log(1+np.exp(Z))\n",
    "    norm_w = np.linalg.norm(w)\n",
    "    c = lambda_ * norm_w ** 2\n",
    "    return value/N + c \n",
    "\n",
    "def function_gradient(X, Y, w, lambda_):\n",
    "    D,N=X.shape\n",
    "    value = np.zeros((D,1))\n",
    "    for i in range(N):       \n",
    "        Z = Y[i] * np.matmul(w.T , (X[:,i]).reshape(D,1))\n",
    "        Q=(Y[i]/(1+np.exp(Z)))*(X[:,i]).reshape(D,1)        \n",
    "        value += Q + 2*lambda_*w\n",
    "        \n",
    "    return value/N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define solvers: GD, SGD, SVRG and SAG. \n",
    "# Setting the values here:\n",
    "\n",
    "alpha = 0 # change the value\n",
    "num_iters = 0 # change the value\n",
    "lambda_ = 0 # change the value\n",
    "epsilon = 0 # change the value\n",
    "\n",
    "# ---------------------- Complete the blank definitions: --------------------------------------\n",
    "\n",
    "def solver(x,y, w, alpha, num_iters , lambda_ , epsilon , optimizer = \"GD\",mem=False):\n",
    "    if (optimizer == \"GD\") :\n",
    "        for i in range(num_iters):\n",
    "            # update the parameter w for GD here:\n",
    "            g=function_gradient(x, y, w, lambda_)\n",
    "            #print(np.linalg.norm(g))\n",
    "            \n",
    "            w=w-alpha*g\n",
    "            if (i%10==0) and (mem):\n",
    "                usage=resource.getrusage(resource.RUSAGE_SELF)\n",
    "                print(\"mem for GD (mb):\", (usage[2]*resource.getpagesize())/1000000.0)\n",
    "            if (np.linalg.norm(g) <= epsilon):\n",
    "                break\n",
    "    elif (optimizer == \"SGD\"):\n",
    "        for i in range(num_iters):\n",
    "            print(i)\n",
    "            # Complete SGD here:\n",
    "                \n",
    "    elif (optimizer == \"SVRG\"):\n",
    "        T = 100\n",
    "        K = math.floor(num_iters/T)\n",
    "        Z = np.matmul(x,np.diagflat(y))\n",
    "        N = x.shape[1]\n",
    "        for k in range(K):\n",
    "            wz = np.matmul(w.T , Z)\n",
    "            diag = np.diagflat(1/(1+np.exp(-1*wz))-np.ones((1,N)))\n",
    "            Ga_ = np.matmul(Z , diag)\n",
    "            ga_ = (1/N) * np.matmul(Ga_ , np.ones((N,1)))\n",
    "            for t in range(T):\n",
    "                # Complete SVRG here:\n",
    "                print(t)\n",
    "            \n",
    "    elif (optimizer == \"SAG\"):\n",
    "        # Complete SAG here:\n",
    "        print(x)\n",
    "            \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of GD after convergence: \n",
      " [[0.0045957 ]\n",
      " [0.00372056]\n",
      " [0.00545639]\n",
      " ...\n",
      " [0.00499467]\n",
      " [0.00065194]\n",
      " [0.00520025]]\n",
      "Cost of GD after convergence:  [[0.00058977]]\n",
      "Training time for GD:  3.592517614364624  sconds\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'asd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-734ebe7b80bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time for GD: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m' sconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0masd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#-------------------- SGD Solver -----------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asd' is not defined"
     ]
    }
   ],
   "source": [
    "## Solving the optimization problem:\n",
    "\n",
    "#y = np.array(Y_train.iloc[0:6000])\n",
    "#x = np.array(X_train.iloc[0:6000,:])\n",
    "D,N = X_train.shape\n",
    "w = np.random.rand(D,1)*0.01  # Initialization of w\n",
    "\n",
    "#-------------------- GD Solver -----------------------\n",
    "start=time.time()\n",
    "num_iters = 50\n",
    "alpha=0.5\n",
    "lambda_=0.01\n",
    "epsilon=0.0001\n",
    "gde = solver(X_train,Y_train,w,alpha,num_iters,lambda_,epsilon,optimizer=\"GD\",mem=False) # complete the command \n",
    "end = time.time()\n",
    "print(\"Weights of GD after convergence: \\n\",gde)\n",
    "cost_value = cost(X_test,Y_test,gde,lambda_)\n",
    "print(\"Cost of GD after convergence: \",cost_value)\n",
    "print(\"Training time for GD: \", end-start , ' sconds')\n",
    "\n",
    "asd\n",
    "\n",
    "#-------------------- SGD Solver -----------------------\n",
    "# complete here :\n",
    "\n",
    "#-------------------- SVRG Solver -----------------------\n",
    "# complete here :\n",
    "\n",
    "#-------------------- SAG Solver -----------------------\n",
    "# complete here :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Executing the iterations and plot the cost function here:\n",
    "\n",
    "ti= np.zeros((50,4))\n",
    "cost_= np.zeros((50,4))\n",
    "for i in range(50):\n",
    "    print(\"......\",i,\".......\")\n",
    "    #--------------GD-------------------\n",
    "    start = time.time()\n",
    "    gde = solver(x.T,y,w,num_iters=i)\n",
    "    end = time.time()\n",
    "\n",
    "    cost_[i,0] = cost(x.T,y,gde)\n",
    "\n",
    "    ti[i,0] = end-start\n",
    "\n",
    "    #---------------SGD------------------\n",
    "    #Complete for SGD solver here :\n",
    "    \n",
    "    #---------------SVRG----------------\n",
    "    #Complete for SVRG solver here :\n",
    "    \n",
    "    #---------------SAG------------------\n",
    "    #Complete for SAG solver here :\n",
    "    \n",
    "    #------------------------------------\n",
    "    \n",
    "    ## Pl the results:\n",
    "    \n",
    "\n",
    "l0 = plt.plot(cost_[:,0],color=\"red\")\n",
    "# complete other plots here: \n",
    "\n",
    "\n",
    "plt.xlabel(\"Number of Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.legend(['GD', 'SGD', 'SVRG', 'SAG'])\n",
    "plt.show()\n",
    "\n",
    "l0 = plt.plot(ti[:,0],color=\"red\")\n",
    "# complete other plots here:\n",
    "\n",
    "plt.xlabel(\"Number of Iteration\")\n",
    "plt.ylabel(\"Time (sec)\")\n",
    "plt.legend(['GD', 'SGD', 'SVRG', 'SAG'])\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tunning the hyper-paramter here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparing different optimizers here: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
